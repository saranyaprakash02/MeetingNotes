# ğŸ“ Meeting Notes & Action Item Extractor

## ğŸ“˜ Project Overview
The **Meeting Notes and Action Item Extractor** is a local AI-powered application that converts **meeting audio** into **structured notes and actionable tasks**.  
It uses **Whisper** for speech-to-text transcription and **LLaMA 3 (via Ollama)** for summarization â€” all running **locally** without internet or API keys.

---

## âš™ï¸ Requirements

### ğŸ§© Software & Libraries
| Component | Purpose | Installation |
|------------|----------|--------------|
| Python 3.10+ | Programming Language | [Python.org](https://www.python.org/) |
| Streamlit | Frontend Web Framework | `pip install streamlit` |
| Faster Whisper | Local Speech-to-Text Model | `pip install faster-whisper` |
| Ollama | Local LLM Engine | [Install Ollama](https://ollama.ai/download) |
| Requests | To communicate with Ollamaâ€™s local API | `pip install requests` |

### ğŸ–¥ï¸ Hardware
- CPU or GPU-supported system (for Whisper processing)
- At least 8 GB RAM recommended
- Disk space: 2â€“4 GB (for Whisper + LLaMA models)

---

## ğŸ§­ Workflow

### Step 1 â€” Upload Audio File
User uploads a meeting recording (`.mp3` or `.wav`) through the Streamlit interface.

### Step 2 â€” Transcription
The **Faster-Whisper model** converts spoken dialogue into text.  
It processes the file locally without cloud services, ensuring privacy.

### Step 3 â€” Summarization and Extraction
Once the transcript is ready, the **LLaMA 3** model (via **Ollama**) is prompted to extract:  
- âœ… **Meeting summary**  
- ğŸ“‹ **Key decisions**  
- ğŸ§¾ **Action items / next steps**  

### Step 4 â€” Output Display
The final structured output is shown on the Streamlit UI as a clear list of meeting notes and actions.

---

## ğŸ§© Solution Architecture

```
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Streamlit   â”‚  â† Upload audio
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚ Faster-Whisperâ”‚  â† Transcribes speech â†’ text
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   LLaMA 3     â”‚  â† Extracts notes & actions
        â”‚   (Ollama)    â”‚
        â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚   Streamlit   â”‚  â† Displays structured output
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§° Setup Instructions

### 1ï¸âƒ£ Install Dependencies
```bash
pip install streamlit faster-whisper requests
```

### 2ï¸âƒ£ Install and Run Ollama
```bash
ollama run llama3
```

### 3ï¸âƒ£ Launch Streamlit App
```bash
streamlit run meeting_notes_app.py
```

---

## âš ï¸ Issues Faced & Rectifications

| Issue | Cause | Solution |
|--------|--------|-----------|
| `ModuleNotFoundError: No module named 'whisper'` | Whisper library not installed | Installed `faster-whisper` instead of deprecated `whisper` |
| `TypeError: argument of type 'NoneType' is not iterable` | Audio not saved correctly before transcription | Ensured file is written using binary mode `wb` |
| `ConnectionError: Could not connect to Ollama` | Ollama service not running | Fixed by running `ollama run llama3` before app execution |
| Model takes long to load | Whisper model loaded multiple times | Used `@st.cache_resource` to load once per session |
| Incomplete or missing summary | Input text too short or unclear | Added clear prompt to guide LLaMA for structured extraction |

---

## ğŸ§  Concepts Involved

| Concept | Description |
|----------|-------------|
| **Automatic Speech Recognition (ASR)** | Converts spoken words into text using Whisper |
| **Transcription** | The process of converting audio to text representation |
| **Summarization** | Condensing long text into key highlights and points |
| **Local LLM (Ollama)** | Runs models like LLaMA 3 locally without external APIs |
| **Prompt Engineering** | Framing clear and specific instructions for LLM output |
| **Streamlit** | Frontend tool for uploading files and displaying results |

---

## ğŸ Outcome
This project demonstrates how meetings can be summarized automatically using **open-source, local AI models**.  
It improves productivity by saving time on manual note-taking and ensures **data privacy** by keeping all processing on the local machine.

---

## ğŸš€ Future Enhancements
- Integrate speaker diarization (who said what)
- Add action item tracking across sessions
- Support multiple meeting formats (Zoom, MS Teams, etc.)
- Provide voice playback for summaries

---

## ğŸ‘©â€ğŸ’» Author
**Saranya P**  
*SEQATO LLM Awareness & Portfolio Development Program â€“ Phase 2 Project*

---

## ğŸ“š References
- [Streamlit Documentation](https://streamlit.io)
- [Faster Whisper GitHub](https://github.com/guillaumekln/faster-whisper)
- [Ollama Models](https://ollama.ai/library)
- [LLaMA 3 Model Overview](https://ai.meta.com/llama/)
